By using Route-finding, mathematical algorithm, that is a natural branch of computer science, that in really talking about is graph theory. 

The problem is that routing algorithms can be extraordinarily complex for even small numbers of possible paths and small numbers of actors.

Traffic, deals with a whole lot of routes and a whole lot of cars (and other "agents," such as traffic lights).

The Nanyang researchers' algorithm starts off by just assuming that, given enough traffic density, shit is going to happen.

They take the assumption that the probability is bigger that zero to occur traffic breakdown, more cars enter in flow that get out, so the goal is to direct the traffic flow so that the overall traffic breakdown probability is minimised.

It then becomes a machine learning problem. 
By taking the current traffic load, adding an unknown additional load that might enter the network at any time, and then coming up with probabilities of network breakdown at each of the network's nodes or intersections, and we wind up with optimal routes through the network.

They were able to demonstrate their algorithm in simulations and are currently working.

* If it is so important as the title says (is it really a big step?) or you think it is more important than the title lets suggests.
Yes
* Which part of ML or AI is used and how is it related to ML or AI.
ML, 
* What did they do to take the data.
Don't say
* Which data did they use.
Don't say
* How did they do to build the model. Which type of model is?
Route-finding
* Do you know any other project that applies the same techniques? Could you use something for another use case?
Don't know. Can be used to management of flow.
* Do you find any ethical implications? Collateral effects?
No
* Do you know any news related?
No