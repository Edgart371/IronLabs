{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RDZFWMK5QH50"
   },
   "source": [
    "# Bonus Challenge: Spiral Data Classification\n",
    "\n",
    "Now that you completed Challenge 2, you know you can use the Tensorflow Playground to experiment the hyperparameters of your deep learning model. If you are brave enough to take on this challenge, we present you the spiral data generated by codes and you will replicate your model built visually in the Tensorflow Playground with Python codes.\n",
    "\n",
    "Below are the codes to generate the spiral dataset. Read the remarks and execute the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LmWM2TxRQH54"
   },
   "outputs": [],
   "source": [
    "from math import hypot, cos, sin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "A function to generate X/Y data points that will form a spiral.\n",
    "\"\"\"\n",
    "def spiral(radius, step, resolution=.1, angle=0.0, start=0.0):\n",
    "    dist = start\n",
    "    coords=[]\n",
    "    while dist*hypot(cos(angle),sin(angle))<radius:\n",
    "        cord=[]\n",
    "        cord.append(dist*cos(angle))\n",
    "        cord.append(dist*sin(angle))\n",
    "        coords.append(cord)\n",
    "        dist+=step\n",
    "        angle+=resolution\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pJ_y4WAiQH55"
   },
   "outputs": [],
   "source": [
    "# Generate two sets of spiral data points with opposite angles\n",
    "data_1 = np.array(spiral(1000, 5, angle=0))\n",
    "data_2 = np.array(spiral(1000, 5, angle=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "cKkoleuYQH56",
    "outputId": "1e65f2c9-953d-42c4-f80d-30a0afe1349e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two datasets to visualize the spirals\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a, b = data_1.T\n",
    "plt.scatter(a, b, s=5)\n",
    "\n",
    "aa, bb = data_2.T\n",
    "plt.scatter(aa, bb, s=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "shv0WpgoQH57",
    "outputId": "5b5828d7-d384-443f-b9c0-e96d469ebfeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    201\n",
       "0    200\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two spiral datasets into one\n",
    "\n",
    "df1 = pd.DataFrame(data=data_1, columns=[\"X\", \"Y\"])\n",
    "df1[\"CLASS\"] = 0\n",
    "\n",
    "df2 = pd.DataFrame(data=data_2, columns=[\"X\", \"Y\"])\n",
    "df2[\"CLASS\"] = 1\n",
    "\n",
    "df = df1.append(df2)\n",
    "df['CLASS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRPzSUmTQH57"
   },
   "source": [
    "Now, build a neural network with Tensorflow to classify `df`. See how low data loss and how high accuracy can you achieve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4GuJbdsCQH58"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "df['xy']=df.X*df.Y\n",
    "df['x2']=df.X**2\n",
    "df['y2']=df.Y**2\n",
    "df['sinx']=np.sin(df.X)\n",
    "df['siny']=np.sin(df.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "eK8v0yEyQnwa",
    "outputId": "cb099170-0cff-4fc1-efc8-bc1ee148829b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-40f43325-1079-4b38-96c8-88e191595ef7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>xy</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>sinx</th>\n",
       "      <th>siny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.975021</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>0</td>\n",
       "      <td>2.483367</td>\n",
       "      <td>24.750832</td>\n",
       "      <td>0.249168</td>\n",
       "      <td>-0.965710</td>\n",
       "      <td>0.478694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.800666</td>\n",
       "      <td>1.986693</td>\n",
       "      <td>0</td>\n",
       "      <td>19.470917</td>\n",
       "      <td>96.053050</td>\n",
       "      <td>3.946950</td>\n",
       "      <td>-0.367099</td>\n",
       "      <td>0.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.330047</td>\n",
       "      <td>4.432803</td>\n",
       "      <td>0</td>\n",
       "      <td>63.522278</td>\n",
       "      <td>205.350257</td>\n",
       "      <td>19.649743</td>\n",
       "      <td>0.981456</td>\n",
       "      <td>-0.961170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.421220</td>\n",
       "      <td>7.788367</td>\n",
       "      <td>0</td>\n",
       "      <td>143.471218</td>\n",
       "      <td>339.341342</td>\n",
       "      <td>60.658658</td>\n",
       "      <td>-0.415358</td>\n",
       "      <td>0.997848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40f43325-1079-4b38-96c8-88e191595ef7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-40f43325-1079-4b38-96c8-88e191595ef7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-40f43325-1079-4b38-96c8-88e191595ef7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           X         Y  CLASS          xy          x2         y2      sinx  \\\n",
       "0   0.000000  0.000000      0    0.000000    0.000000   0.000000  0.000000   \n",
       "1   4.975021  0.499167      0    2.483367   24.750832   0.249168 -0.965710   \n",
       "2   9.800666  1.986693      0   19.470917   96.053050   3.946950 -0.367099   \n",
       "3  14.330047  4.432803      0   63.522278  205.350257  19.649743  0.981456   \n",
       "4  18.421220  7.788367      0  143.471218  339.341342  60.658658 -0.415358   \n",
       "\n",
       "       siny  \n",
       "0  0.000000  \n",
       "1  0.478694  \n",
       "2  0.914754  \n",
       "3 -0.961170  \n",
       "4  0.997848  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GbW7N6wKQytb"
   },
   "outputs": [],
   "source": [
    "X= df.drop(columns='CLASS')\n",
    "y=df.CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YDO3giYuQzrq"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_scaled = normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZxqRuIaQ39X",
    "outputId": "cbee393f-3be2-4e20-fb6b-b3efbf9a81c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 7)\n",
      "(81, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cvUFfRlPQ7E1"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate=0.01\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_dim=7, activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile a model\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam',),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPrGQvF_RPKv",
    "outputId": "9d20e270-a780-4cab-8cc0-912613972dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 11ms/step - loss: 0.7069 - accuracy: 0.4812\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6926 - accuracy: 0.5156\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.5156\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5156\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5156\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5156\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5156\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5156\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5156\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5156\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5156\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5156\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5156\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5156\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5156\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5156\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5156\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5156\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5156\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5156\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5156\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5156\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5156\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5156\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5156\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5156\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5156\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5156\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5156\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5156\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5156\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5156\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5156\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5156\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.5156\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5156\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5156\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5156\n",
      "Accuracy on training data: 0.515625% \n",
      " Error on training data: 0.484375\n",
      "Accuracy on test data: 0.4444444477558136% \n",
      " Error on test data: 0.5555555522441864,\n",
      " Loss: 0.6991895437240601\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=10)\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {},\\n Loss: {}'.format(scores2[1], 1 - scores2[1], scores2[0]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zwaDKlqWSKjh"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate=0.001 #Change the learning rate\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(500, input_dim=7, activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(20,activation='relu'))\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile a model\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam',),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZewe3h4SjZG",
    "outputId": "746b01ac-1f82-431b-f9d1-3f74df7d83de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 1s 6ms/step - loss: 0.6970 - accuracy: 0.4719\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5094\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5063\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5125\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5094\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6919 - accuracy: 0.5188\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5031\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5250\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5250\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.4812\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5188\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.5406\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6924 - accuracy: 0.5250\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.6924 - accuracy: 0.5281\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.4969\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5375\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.5281\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6937 - accuracy: 0.5094\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6922 - accuracy: 0.5250\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5063\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.5375\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5125\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.5219\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.5344\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5437\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6985 - accuracy: 0.5375\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5344\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.5406\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5281\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6863 - accuracy: 0.5406\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5312\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6854 - accuracy: 0.5344\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.5312\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.5375\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.5406\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.5344\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.5594\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.5281\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6772 - accuracy: 0.5469\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6834 - accuracy: 0.5344\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6786 - accuracy: 0.5375\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.5469\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.5344\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.5312\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6772 - accuracy: 0.5375\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6743 - accuracy: 0.5500\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6736 - accuracy: 0.5406\n",
      "Epoch 48/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.5531\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6701 - accuracy: 0.5406\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6745 - accuracy: 0.5531\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.5094\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6707 - accuracy: 0.5469\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.5156\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6693 - accuracy: 0.5594\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.5500\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6729 - accuracy: 0.5375\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6671 - accuracy: 0.5469\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6656 - accuracy: 0.5375\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6611 - accuracy: 0.5500\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5250\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.5281\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6712 - accuracy: 0.5281\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6643 - accuracy: 0.5188\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6634 - accuracy: 0.5469\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.5219\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6565 - accuracy: 0.5531\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6515 - accuracy: 0.5531\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.5094\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.5188\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6508 - accuracy: 0.5375\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6803 - accuracy: 0.5469\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6689 - accuracy: 0.5250\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6623 - accuracy: 0.5250\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6599 - accuracy: 0.5188\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6612 - accuracy: 0.5312\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.5469\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6619 - accuracy: 0.5375\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.5281\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6545 - accuracy: 0.5469\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6749 - accuracy: 0.5188\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6608 - accuracy: 0.5250\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.5250\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.5375\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6485 - accuracy: 0.5406\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.5500\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6572 - accuracy: 0.5188\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6557 - accuracy: 0.5469\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6513 - accuracy: 0.5469\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6530 - accuracy: 0.5437\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.5281\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6537 - accuracy: 0.5469\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.5437\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.5437\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6472 - accuracy: 0.5500\n",
      "Epoch 95/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6456 - accuracy: 0.5562\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.5594\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.5344\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6553 - accuracy: 0.5250\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.5344\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6505 - accuracy: 0.5469\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.5562\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6493 - accuracy: 0.5312\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.5375\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6470 - accuracy: 0.5406\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6455 - accuracy: 0.5437\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6436 - accuracy: 0.5531\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6447 - accuracy: 0.5281\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.5312\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.5531\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6405 - accuracy: 0.5312\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6394 - accuracy: 0.5500\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.5594\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.5688\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6349 - accuracy: 0.5500\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.5750\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.5656\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.5562\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6418 - accuracy: 0.5500\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6280 - accuracy: 0.5656\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.5719\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.5594\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6386 - accuracy: 0.5594\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.5813\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6418 - accuracy: 0.5625\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.5562\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.5656\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.5688\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6379 - accuracy: 0.5594\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.5625\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6409 - accuracy: 0.5531\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6346 - accuracy: 0.5562\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.5719\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6358 - accuracy: 0.5750\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6281 - accuracy: 0.5719\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6194 - accuracy: 0.5719\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.5656\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.5562\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.5719\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.5688\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.5594\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6561 - accuracy: 0.5781\n",
      "Epoch 142/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6499 - accuracy: 0.5562\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.5594\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6350 - accuracy: 0.5719\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.5469\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6223 - accuracy: 0.5750\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6345 - accuracy: 0.5750\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.5656\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6413 - accuracy: 0.5688\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.5625\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.5719\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6183 - accuracy: 0.5688\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6204 - accuracy: 0.5750\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6293 - accuracy: 0.5594\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6154 - accuracy: 0.5719\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6137 - accuracy: 0.5750\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6190 - accuracy: 0.5875\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.5688\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.5781\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6117 - accuracy: 0.5844\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.5906\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.5875\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.5594\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6393 - accuracy: 0.5531\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.5625\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.5562\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6533 - accuracy: 0.5500\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6515 - accuracy: 0.5469\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6438 - accuracy: 0.5469\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6367 - accuracy: 0.5594\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6314 - accuracy: 0.5625\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6271 - accuracy: 0.5375\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.5625\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.5844\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.5656\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6070 - accuracy: 0.5875\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.6031\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.5844\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6408 - accuracy: 0.5500\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6343 - accuracy: 0.5688\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.5844\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.5813\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6038 - accuracy: 0.6000\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.5156\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6412 - accuracy: 0.5312\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6364 - accuracy: 0.4938\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.5156\n",
      "Epoch 188/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.5594\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.5625\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6398 - accuracy: 0.5375\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.5562\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.5500\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6327 - accuracy: 0.5719\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6286 - accuracy: 0.5656\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.5562\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6295 - accuracy: 0.5500\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6282 - accuracy: 0.5562\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6280 - accuracy: 0.5625\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6362 - accuracy: 0.5562\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.5562\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.5719\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.5656\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6292 - accuracy: 0.5781\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.5875\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6191 - accuracy: 0.5938\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.5750\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.5969\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.5625\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6207 - accuracy: 0.5906\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.5656\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6304 - accuracy: 0.5688\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.5656\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.5813\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.5625\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.5906\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.5906\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.5844\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.5844\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5995 - accuracy: 0.5844\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6025 - accuracy: 0.5906\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.5875\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6021 - accuracy: 0.6031\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6170 - accuracy: 0.5938\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5984 - accuracy: 0.6062\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6034 - accuracy: 0.5813\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.5281\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6575 - accuracy: 0.5125\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6458 - accuracy: 0.5562\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.5688\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6369 - accuracy: 0.5750\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.5688\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6307 - accuracy: 0.5656\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6254 - accuracy: 0.5844\n",
      "Epoch 234/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6263 - accuracy: 0.5719\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.5719\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.5656\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6250 - accuracy: 0.5625\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6261 - accuracy: 0.5625\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.5688\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.5594\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6253 - accuracy: 0.5688\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.5781\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.5562\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6244 - accuracy: 0.5844\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.5969\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6256 - accuracy: 0.5719\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.5781\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6227 - accuracy: 0.5906\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.6062\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.6125\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.5875\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6224 - accuracy: 0.5813\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6077 - accuracy: 0.6094\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.6000\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.5312\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6287 - accuracy: 0.5625\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6231 - accuracy: 0.5781\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6508 - accuracy: 0.5375\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.5344\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6465 - accuracy: 0.5344\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.5281\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.5469\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6490 - accuracy: 0.5344\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.5437\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6395 - accuracy: 0.5312\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6337 - accuracy: 0.5625\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6240 - accuracy: 0.5906\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.5469\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.5906\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6156 - accuracy: 0.5844\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6122 - accuracy: 0.6000\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6078 - accuracy: 0.6156\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6406 - accuracy: 0.5906\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6391 - accuracy: 0.5719\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6349 - accuracy: 0.5531\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6317 - accuracy: 0.5625\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.5844\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.5875\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6200 - accuracy: 0.5969\n",
      "Epoch 280/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.7072 - accuracy: 0.5938\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6408 - accuracy: 0.5813\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6355 - accuracy: 0.5688\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6315 - accuracy: 0.5875\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.5938\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6348 - accuracy: 0.5688\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6366 - accuracy: 0.5531\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.5938\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6461 - accuracy: 0.5719\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.5938\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.5719\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6180 - accuracy: 0.5938\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6106 - accuracy: 0.5969\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6203 - accuracy: 0.5844\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.5906\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.6062\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.5844\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.5844\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.6031\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6142 - accuracy: 0.5906\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.5969\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.6000\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5982 - accuracy: 0.5938\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6205 - accuracy: 0.5875\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.5719\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.5750\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6098 - accuracy: 0.5969\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.5906\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.5969\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.6000\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6015 - accuracy: 0.5875\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.5750\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5873 - accuracy: 0.6062\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6130 - accuracy: 0.5656\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5973 - accuracy: 0.5906\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5918 - accuracy: 0.5969\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.5938\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6056 - accuracy: 0.6000\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.6000\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6094\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.5906\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5901 - accuracy: 0.6094\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6114 - accuracy: 0.6094\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.6000\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5818 - accuracy: 0.6500\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5883 - accuracy: 0.5938\n",
      "Epoch 326/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.6094\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5834 - accuracy: 0.6187\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5950 - accuracy: 0.5844\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.5813\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.5969\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5879 - accuracy: 0.6031\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6219\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5973 - accuracy: 0.6313\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5991 - accuracy: 0.6156\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.5906\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6341 - accuracy: 0.5938\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6581 - accuracy: 0.5594\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6280 - accuracy: 0.5469\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5999 - accuracy: 0.6219\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5940 - accuracy: 0.6156\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.6156\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.5846 - accuracy: 0.6250\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6069 - accuracy: 0.5719\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5960 - accuracy: 0.6125\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5860 - accuracy: 0.6375\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.6187\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.6187\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.5938\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5855 - accuracy: 0.6219\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5774 - accuracy: 0.6250\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.6281\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.5844\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6292 - accuracy: 0.5500\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6376 - accuracy: 0.5656\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.5437\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6259 - accuracy: 0.5781\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.5906\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.5875\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.5938\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6329 - accuracy: 0.5594\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.5813\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6295 - accuracy: 0.5656\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6031\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.5969\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.6344\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6055 - accuracy: 0.6250\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.6281\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5829 - accuracy: 0.6344\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.6094\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6000\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6393 - accuracy: 0.5906\n",
      "Epoch 372/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.5969\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6000\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6273 - accuracy: 0.5688\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.5875\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6190 - accuracy: 0.5875\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6192 - accuracy: 0.5844\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6235 - accuracy: 0.5969\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6231 - accuracy: 0.5844\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6195 - accuracy: 0.5813\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6213 - accuracy: 0.5844\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6180 - accuracy: 0.5875\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6795 - accuracy: 0.5469\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6420 - accuracy: 0.5875\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6246 - accuracy: 0.6000\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6524 - accuracy: 0.5719\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6491 - accuracy: 0.5656\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6422 - accuracy: 0.5688\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6372 - accuracy: 0.5750\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.5688\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6335 - accuracy: 0.5813\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6250 - accuracy: 0.5813\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6136 - accuracy: 0.5938\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.5906\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6052 - accuracy: 0.6062\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.6125\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.6125\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6030 - accuracy: 0.6094\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.5906\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6243 - accuracy: 0.5906\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6332 - accuracy: 0.5813\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6119 - accuracy: 0.5813\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6105 - accuracy: 0.5781\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6144 - accuracy: 0.5906\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6203 - accuracy: 0.5719\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6117 - accuracy: 0.5750\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.5781\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6462 - accuracy: 0.5594\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6281 - accuracy: 0.5625\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6227 - accuracy: 0.5594\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6232 - accuracy: 0.5875\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.5781\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.5750\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6068 - accuracy: 0.5813\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.5844\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.5750\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6011 - accuracy: 0.5906\n",
      "Epoch 418/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.5844\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5980 - accuracy: 0.5844\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5917 - accuracy: 0.5938\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.5938\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.5844\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.5938\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5890 - accuracy: 0.6000\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6027 - accuracy: 0.5875\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6089 - accuracy: 0.5906\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6151 - accuracy: 0.6062\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.6000\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6113 - accuracy: 0.6000\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6020 - accuracy: 0.6094\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5926 - accuracy: 0.6062\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5965 - accuracy: 0.5875\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6066 - accuracy: 0.5750\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.5969\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.6062\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5932 - accuracy: 0.5875\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.5781\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6014 - accuracy: 0.5969\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.5938\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5891 - accuracy: 0.6000\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6187\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5798 - accuracy: 0.6219\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.6062\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5690 - accuracy: 0.6250\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.6344\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.6156\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.7241 - accuracy: 0.5656\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 0.6465 - accuracy: 0.5688\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.6354 - accuracy: 0.5437\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.6350 - accuracy: 0.5625\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.6283 - accuracy: 0.5500\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.5719\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6199 - accuracy: 0.5813\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6164 - accuracy: 0.5469\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6153 - accuracy: 0.5844\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.6000\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6109 - accuracy: 0.5813\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.5813\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.5906\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6538 - accuracy: 0.6094\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6552 - accuracy: 0.5000\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6427 - accuracy: 0.5656\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.5406\n",
      "Epoch 464/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6351 - accuracy: 0.5406\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.5656\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.5750\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6286 - accuracy: 0.5656\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6274 - accuracy: 0.5906\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6270 - accuracy: 0.5719\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6270 - accuracy: 0.5875\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6263 - accuracy: 0.5750\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6258 - accuracy: 0.5875\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.5750\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6216 - accuracy: 0.5781\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.5688\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6288 - accuracy: 0.5719\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.5938\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.6000\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.5844\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.5875\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6130 - accuracy: 0.5969\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6182 - accuracy: 0.5625\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6180 - accuracy: 0.5906\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6157 - accuracy: 0.6187\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6033 - accuracy: 0.6062\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.6156\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.6250\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.5938\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6567 - accuracy: 0.6250\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6227 - accuracy: 0.6062\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6172 - accuracy: 0.5719\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6125 - accuracy: 0.6125\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6135 - accuracy: 0.6062\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6064 - accuracy: 0.6000\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.6000\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.6031\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6002 - accuracy: 0.6156\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6018 - accuracy: 0.6094\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6035 - accuracy: 0.6000\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.6219\n",
      "Accuracy on training data: 0.6187499761581421% \n",
      " Error on training data: 0.3812500238418579\n",
      "Accuracy on test data: 0.4938271641731262% \n",
      " Error on test data: 0.5061728358268738,\n",
      " Loss: 0.7707442045211792\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=10)\n",
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {},\\n Loss: {}'.format(scores2[1], 1 - scores2[1], scores2[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "challenge-3 (optional).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
